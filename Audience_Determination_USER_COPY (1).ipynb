{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Audience Determination via Politeness and Formality**\n",
        "\n",
        "**Welcome to our program!**\n",
        "\n",
        "To run our program, you'll need to first select 'runtime' and then 'run all.' Enter your email in the very last code cell when prompted, then follow the directions.\n",
        "\n",
        "We hope you enjoy our program!"
      ],
      "metadata": {
        "id": "nL5fadZ5f-5C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBUY5cJ2rcP6",
        "outputId": "7084fa22-a9db-43bc-ebac-9e17542d4695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 71 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 102 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 112 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 133 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 143 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 153 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 163 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 174 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 184 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 194 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 204 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 225 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 245 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 256 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 266 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 276 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 286 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 296 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 307 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 317 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 327 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 337 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 348 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 358 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 368 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 378 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 389 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 399 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 409 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 419 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 430 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 440 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 450 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 460 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 471 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 481 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 491 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 501 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 512 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 522 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 532 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 542 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 552 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 563 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 573 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 583 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 593 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 604 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 614 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 622 kB 6.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=6f440cca536dfaaf44d612b3ca4561f36fe610d6828637afc0bf5ee05c149c76\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#importing libraries\n",
        "\n",
        "import csv\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk import RegexpParser\n",
        "import itertools\n",
        "from itertools import permutations\n",
        "!pip install autocorrect\n",
        "from autocorrect import Speller\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR35TX4hrkys"
      },
      "outputs": [],
      "source": [
        "#FUNCTIONS\n",
        "\n",
        "def clean(string1):\n",
        "    '''removes punctuation and capitalization'''\n",
        "    string1 = str.lower(string1)\n",
        "    string1 = re.sub(r\"[^\\w\\s]|\\d\", r\" \", string1)\n",
        "    string1 = re.sub(r\"  \", r\" \", string1)\n",
        "    return string1\n",
        "\n",
        "def audience_determiner(politeness, formality):\n",
        "  '''inputs the politeness and formality scores and outputs an audience type'''\n",
        "  if ((politeness < .2) and (formality < 0)) or ((.2 < politeness < .4) and (formality <-.25)):\n",
        "    print(\"\\n A suitable recipient for your email would be:\")\n",
        "    print(\"a CASUAL AUDIENCE or someone YOUNGER or LOWER STATUS than you in a given social context.\")\n",
        "  \n",
        "  elif ((politeness < .2) and (formality >= 0)) or ((.2 <= politeness <= .4) and (-.25 <= formality <= 0)) or ((.4 <= politeness <= .6) and (formality < -.25)):\n",
        "    print(\"\\n A suitable recipient for your email would be:\")\n",
        "    print(\"a NEUTRAL AUDIENCE or someone THE SAME AGE OR STATUS as you in a given social context.\")\n",
        "\n",
        "  elif ((politeness >= .2) and (formality > 0)) or ((politeness > .4) and (formality > -.25)) or ((politeness > .6) and (formality < -.25)):\n",
        "    print(\"\\n A suitable recipient for your email would be:\")\n",
        "    print(\"a RESPECTED AUDIENCE or someone OLDER or HIGHER STATUS as you in a given social context.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g20DnkAPrr8g"
      },
      "outputs": [],
      "source": [
        "#FORMALITY INDICATORS\n",
        "   \n",
        "#greetings (dear sir/madam) and Signatures (sincerely)\n",
        "greetings = [\"dear \", \"hello \", \"hello.\", \"hi \", \"hi.\", \"hey \", \"hey.\", \"good morning\", \"good evening\", \"good afternoon\", \"greetings\", \"to whom this may concern\"]\n",
        "\n",
        "signatures = [\"sincerely,\", \"many thanks,\", \"best,\", \"thanks again,\", \"see you soon,\", \"thank you,\", \"thanks,\"]\n",
        "\n",
        "def greet_sign_finder(email_text):\n",
        "  '''finds greetings in strings'''\n",
        "  greet_sign = []\n",
        "  clean_txt = str.lower(email_text)\n",
        "  #print(clean_txt)\n",
        "\n",
        "  for i in greetings:\n",
        "    if i in clean_txt:\n",
        "      greet_sign.append(i)\n",
        "  for i in signatures:\n",
        "    if i in clean_txt:\n",
        "      greet_sign.append(i)\n",
        "  #print(\"Greetings and signatures:\", greet_sign)\n",
        "  return len(greet_sign)\n",
        "  #print(\"\\n\")\n",
        "  \n",
        "#punctuation\n",
        "def punct_checker(email_text):\n",
        "  no_punct = []\n",
        "  '''checks if punctuation is present'''\n",
        "  punct = re.findall(\"[\\.\\?!,;]\", email_text)\n",
        "  #print(punct)\n",
        "  if len(punct) == 0:\n",
        "    #print(\"No punctuation found.\")\n",
        "    return 0\n",
        "  else:\n",
        "    #print(\"Punctuation: present\")\n",
        "    return 1 #returns 1 point if there is any punctuation in the sentence (1 pt per entire text)\n",
        "    #print(\"\\n\")\n",
        "  \n",
        "#correct spelling\n",
        "def spell_checker(email_text):\n",
        "  '''returns the number of misspelled words'''\n",
        "  #a word is only \"misspelled\" if it is identifiable as an english word\n",
        "  #so for example, 'afjdksl' would not return a misspelling\n",
        "  misspelled_words = []\n",
        "  tokens = word_tokenize(email_text)\n",
        "  for i in tokens:\n",
        "    if i == str.title(i) or i == str.upper(i):\n",
        "      tokens.remove(i)\n",
        "    clean_txt = clean(i)\n",
        "  #clean_txt = clean(email_text)\n",
        "  #tokens = word_tokenize(clean_txt)\n",
        "  spell = Speller(lang='en')\n",
        "  for i in tokens:\n",
        "    spelling = spell(i)\n",
        "    if spelling != i:\n",
        "      misspelled_words.append(i)\n",
        "  #print(\"Misspelled words:\", misspelled_words)\n",
        "  return len(misspelled_words)\n",
        "  #print(\"\\n\")\n",
        "  \n",
        "#correct capitalization\n",
        "def cap_checker(email_text):\n",
        "  '''checks if the first word in a sentence is capitalized'''\n",
        "  #don't use this function for enron corpus since already lowercase\n",
        "  #NO CLEANING in this function\n",
        "  sentences = tokenize.sent_tokenize(email_text)\n",
        "  no_start_cap = []\n",
        "  for i in sentences:\n",
        "    tokens = word_tokenize(i)\n",
        "    if tokens[0] != str.title(tokens[0]):\n",
        "      no_start_cap.append(i)\n",
        "  #print(\"No starting capitalization:\", no_start_cap)\n",
        "  return len(no_start_cap)\n",
        "  #print(\"\\n\")\n",
        "  \n",
        "#formal lexicon\n",
        "formal_lexicon = [\"inquire\", \"temporarily\", \"piqued\", \"fortunate\", \"evening\", \"enchanted\", \"inform\", \"receive\", \"negative\", \"appear\", \"moreover\", \"purchase\", \"must\", \"deficiency\", \"reside\", \"verify\", \"assist\", \"opportunity\",\"utilize\", \"consume\", \"depart\", \"commence\", \"difficult\", \"disclose\", \"express\", \"initially\", \"fortunate\", \"determine\", \"discard\", \"distribute\", \"conceive\", \"perceive\", \"liberate\", \"request\", \"precede\", \"regard\", \"seek\", \"investigate\", \"resemble\", \"consult\", \"considerable\", \"disintegrate\", \"discard\", \"eject\", \"improved\", \"nevertheless\", \"consequently\", \"postpone\", \"resemble\", \"residence\", \"retain\", \"withdraw\", \"suspend\", \"adjourn\", \"additionally\", \"depict\", \"exceptional\", \"subsequently\", \"immediate\", \"sufficient\", \"insufficient\", \"terminate\", \"facilitate\", \"beneficial\", \"pursue\", \"obtain\", \"oppose\", \"haste\", \"notion\", \"envisage\", \"accumulate\", \"eliminate\", \"therefore\", \"thus\", \"endeavor\", \"amount\", \"evaluate\", \"accentuate\", \"revitalize\", \"reevaluate\", \"compensate\"]\n",
        "\n",
        "def formal_lexicon_finder(email_text):\n",
        "  '''finds formal lexicon in string'''\n",
        "  ps = PorterStemmer()\n",
        "  formal_stems = [ps.stem(word) for word in formal_lexicon]\n",
        "  formal_words = []\n",
        "  clean_txt = clean(email_text)\n",
        "  tokens = word_tokenize(clean_txt)\n",
        "  stems = [ps.stem(word) for word in tokens]\n",
        "\n",
        "  for i in stems:\n",
        "    if i in formal_stems:\n",
        "        formal_words.append(i)\n",
        "  #print(\"Formal lexicon:\", formal_words)\n",
        "  return len(formal_words)\n",
        "  #print(\"\\n\")\n",
        "  \n",
        "#no smiley faces, random symbols, emojis\n",
        "emojis = [\":)\", \":))\", \":)))\" \"(:\", \"):\", \":(\", \":-D\", \"D-:\", \":0\", \"0:\", \"<3\", \":P\", \":O\", \"O:\", \";)\", \";(\", \"<3\"]\n",
        "\n",
        "def emoji_finder(email_text):\n",
        "  '''finds emojis/smileys in string'''\n",
        "  expressed_emojis = []\n",
        "  for i in emojis:\n",
        "    if i in email_text:\n",
        "      expressed_emojis.append(i)\n",
        " #print(\"Emojis:\", expressed_emojis)\n",
        "  return len(expressed_emojis)\n",
        "  #print(\"\\n\")\n",
        "  \n",
        "#few interjections/fillers\n",
        "interjections = [\"shh\", \"shhh\", \"psst\", \"shoo\", \"oh\", \"yo\", \"ahem\", \n",
        "                 \"yuck\", \"ew\", \"eww\", \"aw\", \"aww\", \"ugh\", \"phew\", \"phooey\",\n",
        "                 \"yippee\", \"yay\", \"yeah\", \"brr\", \"eek\", \"alas\", \"bingo\", \n",
        "                 \"bravo\", \"eureka\", \"crikey\", \"gee\", \"gosh\", \"god\", \"hm\",\n",
        "                 \"hmm\", \"aha\", \"huh\", \"duh\", \"ah\", \"ahh\", \"wow\", \"yikes\",\n",
        "                 \"crap\", \"dang\", \"yeah\", \"yess\", \"ah\", \"whoops\", \"ope\", \"lol\", \n",
        "                 \"lmao\", \"btw\", \"asap\"]\n",
        "fillers = [\"um\", \"uh\"]\n",
        "\n",
        "def itj_filler_finder(email_text):\n",
        "  '''finds interjections and fillers in string'''\n",
        "  interjections1 = []\n",
        "  fillers1 = []\n",
        "  \n",
        "  clean_txt = clean(email_text)\n",
        "  tokens = word_tokenize(clean_txt)\n",
        "  \n",
        "  for i in interjections:\n",
        "    if i in tokens:\n",
        "      interjections1.append(i)\n",
        "  for i in fillers:\n",
        "    if i in tokens:\n",
        "      fillers1.append(i)\n",
        "\n",
        "  #print(\"Interjections:\", interjections1)\n",
        "  #print(\"Fillers:\", fillers1)\n",
        "  return len(interjections1) + len(fillers1)\n",
        "  #print(\"\\n\")\n",
        "\n",
        "#few contractions\n",
        "def contraction_finder(email_text):\n",
        "  clean_txt = str.lower(email_text)\n",
        "  contractions = re.findall(\"\\w+\\'[^s]{1,2}\", clean_txt)\n",
        "  #print(\"Contractions:\", contractions)\n",
        "  return len(contractions)\n",
        "  #print(\"\\n\")\n",
        "\n",
        "def formality_scorer(y):\n",
        "  '''outputs a numerical score for formality'''\n",
        "  aF = float(greet_sign_finder(y))\n",
        "  bF = float(punct_checker(y))\n",
        "  cF = float(spell_checker(y))\n",
        "  dF = float(cap_checker(y))\n",
        "  eF = float(formal_lexicon_finder(y))\n",
        "  fF = float(emoji_finder(y))\n",
        "  gF = float(itj_filler_finder(y))\n",
        "  hF = float(contraction_finder(y))\n",
        "  result = (aF*.25)+(bF*.25)-(cF*.0625)-(dF*.03125)+(eF*.03125)-(fF*.25)-(hF*.125)\n",
        "  if gF>0:\n",
        "    result == 0\n",
        "  return (result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8C4M3GAr0QO"
      },
      "outputs": [],
      "source": [
        "#POLITENESS INDICATORS\n",
        "\n",
        "#polite words\n",
        "gratitude = [\"thanks\", \"thank you\", \"please\"]\n",
        "apologizing = [\"sorry\", \"apologies\", \"i apologize\", \"oops\", \"whoops\", \"excuse me\"]\n",
        "\n",
        "def polite_word_finder(email_text):\n",
        "  '''checks for polite words in string'''\n",
        "  clean_txt = clean(email_text)\n",
        "  polite_words = []\n",
        "  for i in gratitude:\n",
        "    if i in clean_txt:\n",
        "      polite_words.append(i)\n",
        "  for i in apologizing:\n",
        "    if i in clean_txt:\n",
        "      polite_words.append(i)\n",
        "  #print(\"Polite words:\", polite_words)\n",
        "  return len(polite_words)\n",
        "  #print(\"\\n\")\n",
        "\n",
        "#inclusive we\n",
        "def incl_we_finder(email_text):\n",
        "  '''finds instances of inclusive we (for now, all \"we's\")'''\n",
        "  clean_txt = clean(email_text)\n",
        "  tokens = word_tokenize(clean_txt)\n",
        "  we_list = []\n",
        "\n",
        "  if \"we\" in tokens:\n",
        "    we_list.append(\"we!\")\n",
        "    #print(\"Inclusive 'we':\", we_list)\n",
        "  return len(we_list)\n",
        "\n",
        "#hedging language\n",
        "hedges = [\"apparent\", \"apparently\", \"appear\", \"appeared\", \"appears\", \"approximately\", \"around\", \"assume\", \"assumed\", \"certain amount\", \"certain extent\", \"certain level\", \"claim\", \"claimed\", \"doubt\", \"doubtful\", \"essentially\", \"estimate\", \"estimated\", \"feel\", \"felt\", \"frequently\", \"from our perspective\", \"generally\", \"guess\", \"in general\", \"in most cases\", \"in most instances\", \"in our view\", \"indicate\", \"indicated\", \"largely\", \"likely\", \"mainly\", \"may\", \"maybe\", \"might\", \"mostly\", \"often\", \"on the whole\", \"ought\", \"perhaps\", \"plausible\", \"plausibly\", \"possible\", \"possibly\", \"postulate\", \"postulated\", \"presumable\", \"probable\", \"probably\", \"relatively\", \"roughly\", \"seems\", \"should\", \"sometimes\", \"somewhat\", \"suggest\", \"suggested\", \"suppose\", \"suspect\", \"tend to\", \"tends to\", \"typical\", \"typically\", \"uncertain\", \"uncertainly\", \"unclear\", \"unclearly\", \"unlikely\", \"usually\", \"broadly\", \"tended to\", \"presumably\", \"suggests\", \"from this perspective\", \"from my perspective\", \"in my view\", \"in this view\", \"in our opinion\", \"in my opinion\", \"to my knowledge\", \"fairly\", \"quite\", \"rather\", \"argue\", \"argues\", \"argued\", \"claims\", \"feels\", \"indicates\", \"supposed\", \"supposes\", \"suspects\", \"postulates\"]\n",
        "\n",
        "def hedge_lang_finder(email_text):\n",
        "  '''finds hedgeing words in string'''\n",
        "  clean_txt = clean(email_text)\n",
        "  hedge_lang = []\n",
        "  for i in hedges:\n",
        "    if i in clean_txt:\n",
        "      hedge_lang.append(i)\n",
        "  #print(\"Hedging language:\", hedge_lang)\n",
        "  return len(hedge_lang)\n",
        "  #print(\"\\n\")\n",
        "  \n",
        "#tag questions\n",
        "def tag_question_finder(email_text):\n",
        "  '''finds tag questions in string (ex. We should go, shouldn't we?)'''\n",
        "  sentences = tokenize.sent_tokenize(email_text)\n",
        "  tag_questions = []\n",
        "  #print(sentences)\n",
        "  for i in sentences:\n",
        "    clean_txt = str.lower(i)\n",
        "    tag_questions.append(re.findall(\", \\w+\\'?t? ?\\w+?\\?$\", clean_txt))\n",
        "    for i in tag_questions:\n",
        "      if len(i) == 0:\n",
        "        tag_questions.remove(i)\n",
        "  #print(\"Tag questions:\", tag_questions)\n",
        "  return len(tag_questions)\n",
        "  #print(\"\\n\")\n",
        "\n",
        "#requests\n",
        "req_starters = [\"do\", \"could\", \"can\", \"would\"]\n",
        "req_objects = [\"you\", \"i\"]\n",
        "req_combos = []\n",
        "\n",
        "permut = itertools.permutations(req_starters, len(req_objects)) # Getting all permutations of req_starters with length of req_objects\n",
        "for comb in permut: # zip() is called to pair each permutation and shorter list element into combination\n",
        "    zipped = zip(comb, req_objects)\n",
        "    req_combos.append(list(zipped))\n",
        "\n",
        "req_combos_flat = [] #flattening multidimentional list\n",
        "for i in req_combos:\n",
        "    for j in i:\n",
        "        req_combos_flat.append(j)\n",
        "req_combos_flat = list(set(req_combos_flat)) #purging duplicates from list\n",
        "req_combos_flat.append((\"may\", \"i\")) #adding additional request forms\n",
        "req_combos_flat.append((\"will\", \"you\"))\n",
        "\n",
        "def request_finder(email_text):\n",
        "  '''finds syntactic requests'''\n",
        "  sentences = tokenize.sent_tokenize(email_text)\n",
        "  clean_sents = []\n",
        "  tokens = []\n",
        "  requests = []\n",
        "\n",
        "  for i in sentences: #cleaning and tokenizing the sentences\n",
        "      clean_sents.append(clean(i))\n",
        "  for i in clean_sents:\n",
        "      tokens.append(word_tokenize(i))\n",
        "\n",
        "  for i in range(0, (len(tokens)-1)):\n",
        "      s = tokens[i]\n",
        "      orig = sentences[i]\n",
        "      for p in req_combos_flat:\n",
        "          if p[0] in s: #checking whether a request starter is in the list\n",
        "              if (s.index(p[0]) + 1) >= len(s): #dealing with list boundaries\n",
        "                  continue\n",
        "              if tokens[tokens.index(s)][s.index(p[0]) + 1] == p[1] or tokens[tokens.index(s)][s.index(p[0]) - 1] == p[1] : #checking adjacent words for request objects\n",
        "                  if re.match(r\", \\w+\\'? \\w+\\?$\", sentences[s.index(p[0]) + 1]): #checks that it isn't a tag question\n",
        "                      print(\"none\")\n",
        "                  else:\n",
        "                      requests.append(orig)\n",
        "  #print(\"Requests:\", requests)\n",
        "  return len(requests)\n",
        "  #print(\"\\n\")\n",
        "\n",
        "#commands\n",
        "# ^ or CONJ (don't)? VB\n",
        "def command_finder(email_text):\n",
        "  '''finds syntactic imperatives in the email'''\n",
        "  commands = []\n",
        "  clean_txt = str.lower(email_text)\n",
        "  sentences = tokenize.sent_tokenize(email_text)\n",
        "  #tokenizer = word_tokenize(clean_txt)\n",
        "  tokens = word_tokenize(clean_txt)\n",
        "  tags = nltk.pos_tag(tokens)\n",
        "\n",
        "  for j in sentences:\n",
        "        if \"?\" in j:\n",
        "          print(\"not a command\")\n",
        "        else:\n",
        "          for i in tokens:\n",
        "              chunkGram = r\"\"\"Chunk: {(don t|do not|never|always)?<VB>}\"\"\"\n",
        "              chunkParser = nltk.RegexpParser(chunkGram)\n",
        "              chunked = chunkParser.parse(tags)\n",
        "              #print(chunked)\n",
        "              chunked_string = str(chunked)\n",
        "              if \"Chunk\" in chunked_string:\n",
        "                #print(\"command found.\")\n",
        "                commands.append(j)\n",
        "              break\n",
        "  #print(\"Commands:\", commands)\n",
        "  return len(commands)\n",
        "  #print(\"\\n\")\n",
        "\n",
        "#qualifiers\n",
        "qualifiers = [\"quite\", \"rather\", \"somewhat\", \"just\", \"indeed\", \"still\", \"almost\", \"fairly\", \"pretty\", \"even\", \"a bit\", \"a little\", \"a lot\", \"a whole lot\", \"a good deal\", \"a great deal\", \"kind of\", \"sort of\"]\n",
        "\n",
        "def qual_finder(email_text):\n",
        "  '''finds qualifiers in string'''\n",
        "  #list POS tags, if RB (adverb) is in qualifiers list, then return it\n",
        "  qualifiers1 = []\n",
        "  clean_txt = clean(email_text)\n",
        "  tokens = word_tokenize(clean_txt)\n",
        "  tags = nltk.pos_tag(tokens)\n",
        "\n",
        "  for i in tags:\n",
        "      if i[1] == \"RB\":\n",
        "          if i[0] in qualifiers:\n",
        "              qualifiers1.append(i[0])\n",
        "            \n",
        "  lower = str.lower(email_text)\n",
        "  for i in qualifiers:\n",
        "    if i in lower:\n",
        "      if i not in qualifiers1:\n",
        "        qualifiers1.append(i)\n",
        "  \n",
        "  #print(\"Qualifiers:\", qualifiers1)\n",
        "  return len(qualifiers1)\n",
        "  #print(\"\\n\")\n",
        "\n",
        "#curse words\n",
        "curses = [\"damn\", \"shit\", \"fuck\", \"goddamn\", \"goddamnit\",  \"motherfucker\", \"whore\", \"dick\", \"dickhead\", \"asshole\", \"ass\", \"bastard\", \"bitch\", \"cunt\", \"hell\", \"slut\"]\n",
        "\n",
        "def curse_word_finder(email_text):\n",
        "  '''finds curse words in string'''\n",
        "  ps = PorterStemmer()\n",
        "  curse_stems = [ps.stem(word) for word in curses]\n",
        "  expressed_curses = []\n",
        "  clean_txt = clean(email_text)\n",
        "  tokens = word_tokenize(clean_txt)\n",
        "  stems = [ps.stem(word) for word in tokens]\n",
        "  for i in stems:\n",
        "    if i in curse_stems:\n",
        "      expressed_curses.append(i)\n",
        "  #print(\"Curses:\", expressed_curses)\n",
        "  return len(expressed_curses)\n",
        "\n",
        "def misc_pol(email_text):\n",
        "  '''finds miscellaneous polite language in string'''\n",
        "  misc = []\n",
        "  misc_polite = [\"if so\", \"if you can\", \"if you could\", \"you can\", \"your earliest convenience\"]\n",
        "  positive_words = [\"beautiful\", \"great\", \"wonderful\", \"excellent\", \"amazing\", \"super\", \"supurb\", \"wonderful\", \"well done\", \"good job\", \"good work\", \"great work\", \"fantastic\"]\n",
        "  clean_txt = clean(email_text)\n",
        "  polite_words = []\n",
        "  for i in misc_polite:\n",
        "    if i in clean_txt:\n",
        "      misc.append(i)\n",
        "  for i in positive_words:\n",
        "    if i in clean_txt:\n",
        "      misc.append(i)\n",
        "  #print(\"Miscellaneous polite:\", misc)\n",
        "  return len(misc)\n",
        "  #print(\"\\n\")\n",
        "\n",
        "\n",
        "def politeness_scorer(x):\n",
        "  '''outputs a numerical score for politeness'''\n",
        "  aP = float(polite_word_finder(x))\n",
        "  bP = float(incl_we_finder(x))\n",
        "  cP = float(hedge_lang_finder(x))\n",
        "  dP = float(tag_question_finder(x))\n",
        "  #eP = float(command_finder(x))\n",
        "  fP = float(qual_finder(x))\n",
        "  gP = float(curse_word_finder(x))\n",
        "  hP = float(misc_pol(x))\n",
        "  #iP = float(request_finder(x))\n",
        "  result = (aP*.25)+(cP*.25) +(fP*.125)+(dP*.0625)+(hP*.0625)+(bP*.0625)#+(iP*.125) #need to add eP HERE\n",
        "  #-(eP*.0625)\n",
        "  if gP>0:\n",
        "      result = 0\n",
        "  return (result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#user interface\n",
        "\n",
        "instructions = \"This program analyzes emails for politeness and formality and predicts an intended audience. \\n \\n\"\n",
        "print(instructions)\n",
        "\n",
        "run = True\n",
        "while run == True:\n",
        "  user_email = input(\"Please enter the body text of your email: \\n\")\n",
        "\n",
        "  user_p_score = politeness_scorer(user_email)\n",
        "  #print(\"\\n Politeness score:\", user_p_score, \"\\n \\n\")\n",
        "  user_f_score = formality_scorer(user_email)\n",
        "  #print(\"\\n Formality score:\", user_f_score, \"\\n \\n\")\n",
        "\n",
        "  #audience categorizing\n",
        "  audience_determiner(user_p_score, user_f_score)\n",
        "  \n",
        "  #Check to see if user's intentions matched audience category\n",
        "  print(\"\\n \\n Was this your intended audience for your email?\")\n",
        "  print(\"Enter 'y' for yes, 'n' for no.\")\n",
        "  choice_1 = input()\n",
        "\n",
        "  valid = True\n",
        "  while valid == True:\n",
        "    if str.lower(choice_1) not in [\"y\", \"n\"]:\n",
        "      print(\"Please type 'y' or 'n'.\")\n",
        "      choice_1 = input()\n",
        "    else:\n",
        "      valid = False\n",
        "\n",
        "  if choice_1 == \"y\":\n",
        "    print(\"\\n Good work! Your email is appropriately polite and formal for your intended audience.\")\n",
        "    print(\"\\n Would you like to enter another email or quit the program?\")\n",
        "    print(\"Type 'quit' to quit. Type anything else to enter another email.\")\n",
        "    quit = input()\n",
        "    if quit == \"quit\":\n",
        "      break\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  else: #giving suggestions\n",
        "    print(\"Would you like to see suggestions for increasing your politeness and formality?\")\n",
        "    print(\"Enter 'y' for yes, 'n' for no.\")\n",
        "    choice_2 = input()\n",
        "\n",
        "    valid = True\n",
        "    while valid == True:\n",
        "      if str.lower(choice_2) not in [\"y\", \"n\"]:\n",
        "        print(\"Please type 'y' or 'n'.\")\n",
        "        choice_2 = input()\n",
        "      else:\n",
        "        valid = False\n",
        "\n",
        "    if choice_2 == \"y\":\n",
        "      print(\"Who is your intended audience? Type the number corresponding to your audience category.\")\n",
        "      print(\"1 A FRIEND \\n 2 A FAMILY MEMBER \\n 3 A MENTOR, PROFESSOR, OR TEACHER, \\n 4 A CO-WORKER OR COLLEAGUE\")\n",
        "      choice_3 = input()\n",
        "\n",
        "      valid = True\n",
        "      while valid == True:\n",
        "        if choice_3 not in [\"1\", \"2\", \"3\", \"4\"]:\n",
        "          print(\"Please select a choice 1-4.\")\n",
        "          choice_3 = input()\n",
        "        else:\n",
        "          valid = False\n",
        "\n",
        "      print(\"What is the age or status of your intended audience? Type the number corresponding to the category.\")\n",
        "      print(\"1 YOUNGER/LOWER STATUS THAN ME \\n 2 THE SAME AGE/STATUS AS ME \\n 3 OLDER/HIGHER STATUS THAN ME\")\n",
        "      choice_4 = input()\n",
        "\n",
        "      valid = True\n",
        "      while valid == True:\n",
        "        if choice_4 not in [\"1\", \"2\", \"3\"]:\n",
        "          print(\"Please select a choice 1-3.\")\n",
        "          choice_4 = input()\n",
        "        else:\n",
        "          valid = False\n",
        "\n",
        "      if choice_3 == \"1\" and choice_4 == \"1\":\n",
        "        print(\"When speaking to a friend younger/lower status than you, you can use informal, less polite language if you desire.\")\n",
        "      elif choice_3 == \"1\" and choice_4 == \"2\":\n",
        "        print(\"When speaking to a friend the same age/status as you, you can use informal, less polite language if you desire.\")\n",
        "      elif choice_3 == \"1\" and choice_4 == \"3\":\n",
        "        print(\"When speaking to a friend older/higher status than you, use polite, semi-formal language. Remember to say please and thank you, and using greetings and farewells is suggested.\")\n",
        "      elif choice_3 == \"2\" and choice_4 == \"1\":\n",
        "        print(\"When speaking to a family member younger/lower status than you, use moderately polite, relatively informal \\n language. You should model politeness to younger cousins or siblings, with words such as please and thank you, but you may use an informal tone.\")\n",
        "      elif choice_3 == \"2\" and choice_4 == \"2\":\n",
        "        print(\"When speaking to a family member the same age/status as you, you can use informal, less polite language if you desire.\")\n",
        "      elif choice_3 == \"2\" and choice_4 == \"3\":\n",
        "        print(\"When speaking to a family member older/higher status than you, use very polite language, such as please \\n and thank you, with moderate formality. Be sure to use moderately formal greetings and signatures, capitalize your words, and fix misspellings.\")\n",
        "      elif choice_3 == \"3\" and choice_4 == \"1\":\n",
        "        print(\"The audience situation you indicated is unlikely to occur. A mentor, professor, or teacher is likely to \\n be a higher status than you. Even if, for some reason, this situation did occur, you still ought to use very polite and formal language, seeing as how you are learning from a mentor/teacher and should want to impress them. Please, thank you, greetings and signatures, proper capitalization, and proper spellings are important.\")\n",
        "      elif choice_3 == \"3\" and choice_4 == \"2\":\n",
        "        print(\"When speaking to a mentor, professor, or teacher the same age/status as you, use moderate politeness and \\n formality. Use greetings, signatures, and polite words such as please and thank you, but an informal tone is acceptable in most cases. \\n You should still, however, use proper capitalization, punctuation, and spelling.\")\n",
        "      elif choice_3 == \"3\" and choice_4 == \"3\":\n",
        "        print(\"When speaking to a mentor, professor, or teacher older/higher status than you, always use be highly polite \\n and formal. Use greetings, signatures, and polite words such as please and thank you, and avoid more informal slang. \\n Proofread to fix typos, misspellings, and improper capitalization/punctuation. \\n Avoid using emojis, filler words, rude words, or interjections. When asking for something, hedge your request \\n with qualifier words.\")\n",
        "      elif choice_3 == \"4\" and choice_4 == \"1\":\n",
        "        print(\"When speaking to a co-worker or colleague younger/lower status than you, you may use informal, but polite, language. \\n Greetings, signatures, and proper capitalization/punctuation is suggested but not always necessary, but \\n make requests instead of commands, and always say please and thank you.\")\n",
        "      elif choice_3 == \"4\" and choice_4 == \"2\":\n",
        "        print(\"When speaking to a co-worker or colleague the same age/status as you, you may use informal language and moderate \\n politeness. You may address the recipient as if they were a friend, but be careful to make requests \\n politely and qualify any direct or negative statements. The words please and thank you are suggested.\")\n",
        "      elif choice_3 == \"4\" and choice_4 == \"3\":\n",
        "        print(\"When speaking to a co-worker or colleague older/higher status than you, use highly polite, semi-formal \\n language. Use greetings and signatures, and proofread your email for capitalization, punctuation, \\n and grammatical errors. Using the words please and thank you are always polite, and ensure that you leave out any rude words.\")\n",
        "\n",
        "    print(\"\\n Would you like to enter another email or quit the program?\")\n",
        "    print(\"Type 'quit' to quit. Type anything else to enter another email.\")\n",
        "    quit = input()\n",
        "    if quit == \"quit\":\n",
        "      break\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "    valid = True\n",
        "    while valid == True:\n",
        "      if str.lower(choice_2) not in [\"y\", \"n\"]:\n",
        "        print(\"Please type 'y' or 'n'.\")\n",
        "        choice_2 = input()\n",
        "      else:\n",
        "        valid = False\n",
        "    if choice_5 == \"n\":\n",
        "      run = False\n",
        "\n",
        "sample_email_1 = \"Hi Teresa, Just a quick question about the RSVP form. The form only lets me enter one email address for the mentor section, if I enter my primary faculty advisor is there a way it can be forwarded to my graduate student mentor as well? Thanks\"\n",
        "sample_email_2 = \"Good evening, Dean Moore, I am just reaching out for an update on the letter to the editor. How is it going? Do you think you would be able to have it to me by Tuesday? Best,\" \n",
        "sample_email_3 = \"Love you <3 these are for you AND Dad!\"\n",
        "sample_email_4 = \"Hey Emily, I’m not on the weekly schedule. I know I sent in my form, is there some way I could hop on the Friday afternoon shift? It was the only one I could take\""
      ],
      "metadata": {
        "id": "CPEsI0vvUamx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Audience_Determination_USER COPY.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}